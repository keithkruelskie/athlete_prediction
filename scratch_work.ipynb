{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas_read_xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple Health Data Try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in xml files, when I thought I might need apple data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_read_xml as pdx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/apple_health_export_brian_mclain/export.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cd6a971af5f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/apple_health_export_brian_mclain/export.xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas_read_xml.py\u001b[0m in \u001b[0;36mread_xml\u001b[0;34m(path_or_xml, root_key_list, transpose, encoding)\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mread_xml_files_in_double_zip_as_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_key_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath_or_xml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mread_xml_as_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_xml_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_xml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_key_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mread_xml_as_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_xml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_key_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas_read_xml.py\u001b[0m in \u001b[0;36mread_xml_from_path\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_xml_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/apple_health_export_brian_mclain/export.xml'"
     ]
    }
   ],
   "source": [
    "df = pdx.read_xml(\"./data/apple_health_export_brian_mclain/export.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getsizeof(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree\n",
    "import datetime\n",
    "\n",
    "path_to_exportxml = \"./data/apple_health_export_brian_mclain/export.xml\"\n",
    "\n",
    "def iter_records(healthdata):\n",
    "    healthdata_attr = healthdata.attrib\n",
    "    for rec in healthdata.iterfind('.//Record'):\n",
    "        rec_dict = healthdata_attr.copy()\n",
    "        rec_dict.update(healthdata.attrib)\n",
    "        for k, v in rec.attrib.items():\n",
    "            if 'date' in k.lower():\n",
    "                rec_dict[k] = datetime.datetime.strptime(v, '%Y-%m-%d %H:%M:%S %z')\n",
    "            else:\n",
    "                rec_dict[k] = v\n",
    "        yield rec_dict\n",
    "\n",
    "e = xml.etree.ElementTree.parse(path_to_exportxml).getroot()\n",
    "df = pd.DataFrame(list(iter_records(e)))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_walk_df = df[(df['type'] == 'HKQuantityTypeIdentifierDistanceWalkingRunning')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/b_mclain_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = pd.to_numeric(df['value'])\n",
    "df['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_walk_df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_walk_df['value'] = pd.to_numeric(run_walk_df['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_walk_df['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_walk_df[run_walk_df['value']>.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_walk_df['creationDate'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df = df[(df['type'] == 'HKQuantityTypeIdentifierDistanceWalkingRunning') | (df['type'] == 'HKQuantityTypeIdentifierWalkingSpeed')| (df['type'] == 'HKQuantityTypeIdentifierAppleExerciseTime')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(run_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df['date']=pd.to_datetime(run_df['creationDate'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df['date'].iloc[0].day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = []\n",
    "month = []\n",
    "year = []\n",
    "\n",
    "for i in range(len(run_df)):    \n",
    "    day.append(run_df['date'].iloc[i].day)\n",
    "    month.append(run_df['date'].iloc[i].month)\n",
    "    year.append(run_df['date'].iloc[i].year)\n",
    "\n",
    "run_df['day'] = day\n",
    "run_df['month'] = month\n",
    "run_df['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_object = []\n",
    "for i in range(len(run_df)):    \n",
    "    date_object.append(str(run_df.iloc[0]['month'])+' '+str(run_df.iloc[0]['day'])+' '+str(run_df.iloc[0]['year']))\n",
    "run_df['date_object']= date_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Apple Health Kit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garmin Data Scratch Work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkk = pd.read_csv('./data/raw/Garmin/ActivitiesBKK2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkk_running = bkk[bkk['Activity Type'] == 'Running']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkk_running['Distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkk_running['Distance'] = bkk_running['Distance'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkk_running['Distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkk_running[bkk_running['Distance'] >= 12.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb = pd.read_csv('./data/raw/Garmin/02_eric_bayless_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb['Race'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb[eb['Race'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb = pd.read_csv('./data/raw/Garmin/06_jen-all-activities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(jb['Distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jb.drop(index=260, inplace=True)\n",
    "jb[jb['Activity Type'] == 'Running']['Distance'].astype('float').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb[jb['Activity Type'] == 'Running']['Distance'].astype('float').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb.loc[379]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lars = pd.read_csv('./data/raw/Lars-Strava/activities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lars['Activity Description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joe = pd.read_csv('./data/raw/Garmin/09_Riggs Activities r4 w favorites.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joe Tagged his races and hard efforts as favorites\n",
    "joe[joe['Favorite'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test importation of data and race dates and prep for simple time series model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ast and ast.literal_eval let us turn a string into a list pythonically https://stackoverflow.com/questions/1894269/how-to-convert-string-representation-of-list-to-a-list\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-04-12',\n",
       " '2016-07-17',\n",
       " '2016-09-25',\n",
       " '2016-09-25',\n",
       " '2016-12-03',\n",
       " '2016-12-17',\n",
       " '2017-01-07',\n",
       " '2017-01-28',\n",
       " '2017-04-09',\n",
       " '2017-04-09',\n",
       " '2017-04-22',\n",
       " '2017-04-22',\n",
       " '2017-04-22',\n",
       " '2017-11-11',\n",
       " '2017-12-02',\n",
       " '2017-12-16',\n",
       " '2018-03-24',\n",
       " '2018-04-21',\n",
       " '2019-11-16',\n",
       " '2020-03-05',\n",
       " '2020-05-10']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 9\n",
    "with open(\"./data/athletes.json\") as json_file: \n",
    "    data = json.load(json_file)\n",
    "    races = ast.literal_eval(data[f\"{n}\"]['race_date_list'])\n",
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_09_df = pd.read_csv('./data/raw/Garmin/09_Riggs Activities r4 w favorites.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.0\n",
       "1    7:20\n",
       "2    21.8\n",
       "3    8:08\n",
       "4    21.6\n",
       "Name: Avg Speed, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athlete_09_df['Avg Speed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7:20\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(\"\\d?\\d:\\d\\d\", athlete_09_df['Avg Speed'][1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_transf_garmin2(filepath, athlete_id, race_dates): #Filepath is the csv filepath, athlete_id is a counter variable, race_dates is the list of race dates\n",
    "    \n",
    "    #Read in the dataframe:\n",
    "    df = pd.read_csv(filepath)\n",
    "    #Found out this is very important in garmin files:\n",
    "    df.replace('--', 0, inplace = True)\n",
    "    \n",
    "    #Create athlete_id, file type and race category column:\n",
    "    df['athlete_id'] = athlete_id\n",
    "    df['filetype'] = 'garmin'\n",
    "    df['is_race'] = 0\n",
    "    \n",
    "    #Apparently some garmins save different columns:\n",
    "    if 'Avg Speed' in df.columns:\n",
    "        print(\"We have an Avg Speed Column!\")\n",
    "        df['Avg Pace'] = 0\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            #print(df['Avg Speed'][i])\n",
    "            try:\n",
    "                df['Avg Pace'][i] = re.findall(\"\\d?\\d:\\d\\d\", df['Avg Speed'][i])[0]\n",
    "                #print(df['Avg_Pace'][i])\n",
    "            except:\n",
    "                df['Avg Pace'][i] = '00:00:00'\n",
    "        #Best we can do for now is set the best pace to the average pace:\n",
    "        df['Best Pace'] = df['Avg Pace']\n",
    "    \n",
    "    \n",
    "    #Define the columns to have their data types transformed:\n",
    "    obj_to_num_cols = ['Calories', 'Avg HR', 'Max HR', 'Aerobic TE', 'Avg Run Cadence', 'Max Run Cadence', 'Elev Gain', 'Elev Loss', 'Avg Run Cadence.1', 'Avg Power', 'Max Power']\n",
    "    pace_cols = ['Avg Pace', 'Best Pace']\n",
    "    \n",
    "    #Convert the numeric columns:\n",
    "    for col in obj_to_num_cols:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col].str.extract(r'd+'))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    #Convert the pace columns:\n",
    "    for col in pace_cols:\n",
    "        for i in range(len(df[col])):\n",
    "            try:\n",
    "                df[col][i] = pd.to_timedelta('00:'+df[col][i])\n",
    "            except:\n",
    "                #print(f'col={col}')\n",
    "                #print(f'i= {i}')\n",
    "                #print(f'df[col][i] = {df[col][i]}')\n",
    "                if df[col][i]==0:\n",
    "                    df[col][i] = pd.to_timedelta('00:00:00')\n",
    "                else:\n",
    "                    pass\n",
    "                pass\n",
    "    \n",
    "    #Clean up the column names:\n",
    "    #This is to remove the (R) logo so it doesn't cause any issues later:\n",
    "    r_logo = df.columns[df.columns.str.contains('Training Stress')][0][-1]\n",
    "    #Clean up the column names:\n",
    "    df.columns = df.columns.str.replace('/', '').str.lower().str.replace('.', '_').str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace(r_logo, '')\n",
    "    df.set_index(df['date'], inplace = True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    ###Write a function to change the race dates in race_dates to a '1'\n",
    "    \n",
    "    #Write out the file to the data folder:\n",
    "    df.to_csv(f'./data/clean/garmin_clean/clean_{athlete_id}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = ['2020-10-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './data/raw/Garmin/06_jen-all-activities.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_transf_garmin2(filepath, 6, races)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_9 = pd.read_csv('./data/clean/garmin_clean/clean_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_filepath = './data/clean/garmin_clean/clean_9.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_9['is_race'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_transf_garmin(filepath, athlete_id, race_dates): #Filepath is the csv filepath, athlete_id is a counter variable, race_dates is the list of race dates\n",
    "    \n",
    "    #Read in the dataframe:\n",
    "    df = pd.read_csv(filepath)\n",
    "    #Found out this is very important in garmin files:\n",
    "    df.replace('--', 0, inplace = True)\n",
    "    \n",
    "    #Create athlete_id, file type and race category column:\n",
    "    df['athlete_id'] = athlete_id\n",
    "    df['filetype'] = 'garmin'\n",
    "    df['is_race'] = 0\n",
    "    \n",
    "    \n",
    "    #Define the columns to have their data types transformed:\n",
    "    obj_to_num_cols = ['Calories', 'Avg HR', 'Max HR', 'Aerobic TE', 'Avg Run Cadence', 'Max Run Cadence', 'Elev Gain', 'Elev Loss', 'Avg Run Cadence.1', 'Avg Power', 'Max Power']\n",
    "    pace_cols = ['Avg Pace', 'Best Pace']\n",
    "    \n",
    "    #Convert the numeric columns:\n",
    "    for col in obj_to_num_cols:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col].str.extract(r'd+'))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    #Convert the pace columns:\n",
    "    for col in pace_cols:\n",
    "        for i in range(len(df[col])):\n",
    "            try:\n",
    "                df[col][i] = pd.to_timedelta('00:'+df[col][i])\n",
    "            except:\n",
    "                #print(f'col={col}')\n",
    "                #print(f'i= {i}')\n",
    "                #print(f'df[col][i] = {df[col][i]}')\n",
    "                if df[col][i]==0:\n",
    "                    df[col][i] = pd.to_timedelta('00:00:00')\n",
    "                else:\n",
    "                    pass\n",
    "                pass\n",
    "    \n",
    "    #Clean up the column names:\n",
    "    #This is to remove the (R) logo so it doesn't cause any issues later:\n",
    "    r_logo = df.columns[df.columns.str.contains('Training Stress')][0][-1]\n",
    "    #Clean up the column names:\n",
    "    df.columns = df.columns.str.replace('/', '').str.lower().str.replace('.', '_').str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace(r_logo, '')\n",
    "    df.set_index(df['date'], inplace = True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    ###Write a function to change the race dates in race_dates to a '1'\n",
    "    \n",
    "    #Write out the file to the data folder:\n",
    "    df.to_csv(f'./data/clean/garmin_clean/clean_{athlete_id}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_for_prediction(df_filepath, athlete_dict):\n",
    "    \n",
    "    '''\n",
    "    Inputs: csv filepath, and athlete dictionary\n",
    "    -Dictionary contains an entry for race date, keyed to athlete id\n",
    "    Outputs: \n",
    "        1) a csv with races indicated, indexed by time series\n",
    "        2) a csv with summary values for 1 week, 2 weeks, 1 month, 2 months, 3 months\n",
    "            - If values are not available, they will be 0s\n",
    "    '''\n",
    "    #Read in the csv:\n",
    "    working = pd.read_csv(df_filepath, index_col='date').drop('date.1', axis =1)\n",
    "    \n",
    "    athlete_id = working['athlete_id'][0]\n",
    "    \n",
    "    #get the race dates for the selected athlete:\n",
    "    race_dates = athlete_dict[athlete_id]['race_date_list']\n",
    "    \n",
    "    #Set the index as a datetime:\n",
    "    working.index = pd.to_datetime(working.index)\n",
    "    \n",
    "    #Create a month interval: (we can multiply by 3 to get the 3 month values)\n",
    "    month = timedelta(31)\n",
    "    day = timedelta(1)\n",
    "    \n",
    "    #Create a time of day column:\n",
    "    time_of_day = [re.findall(\"\\d\\d:\\d\\d:\\d\\d\", working.index.to_series().astype('str')[i])[0] for i in range(len(working))]\n",
    "    \n",
    "    #Drop the hours and minutes and seconds:\n",
    "    working.index = pd.DatetimeIndex(working.index).normalize()\n",
    "    \n",
    "    #Label all of the races:\n",
    "    working['is_race'] = np.where(working.index.isin(race_dates), 1, 0)\n",
    "    \n",
    "    #Create a folder for the athlete to keep things tidy:\n",
    "    parent_path = './data/races'\n",
    "    directory = f'athlete_{athlete_id}'\n",
    "    path = os.path.join(parent_path, directory)\n",
    "    os.mkdir(path)\n",
    "    \n",
    "    \n",
    "    #select the last month and last 3 months of data from the working file, and export them as separate csvs to the 'races' folder:\n",
    "    \n",
    "    for i in range(len(race_dates)):\n",
    "        #i is the counter, find the 1 month and 3 month data:\n",
    "        rd = pd.to_datetime(race_dates[i])\n",
    "        race_1_mo_back = working[rd+day:rd-month]\n",
    "        race_1_mo_back.sort_index(inplace=True)\n",
    "        race_1_mo_back.to_csv(f'{path}/athlete_{athlete_id}_race_{i}_1_mo.csv')\n",
    "        try:\n",
    "            #This way if there is not 3 months data, it just skips out.\n",
    "            race_3_mo_back = working[rd+day:(rd-month*3)]\n",
    "            race_3_mo_back.sort_index(inplace=True)\n",
    "            race_3_mo_back.to_csv(f'{path}/athlete_{athlete_id}_race_{i}_3_mo.csv')\n",
    "        except:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_athlete_dict = {2:{'race_date_list':['2020-05-09'],\n",
    "                          'age':35, 'gender':'F', \n",
    "                          'race_count':1, \n",
    "                          'training_elevation':1000, \n",
    "                          'max_hr':175}, \n",
    "                     9:{'race_date_list':['2016-04-12', '2016-07-17', '2016-09-25', '2016-09-25', '2016-12-03', '2016-12-17', '2017-01-07', '2017-01-28', '2017-04-09', '2017-04-09', '2017-04-22', '2017-04-22', '2017-04-22', '2017-11-11', '2017-12-02', '2017-12-16', '2018-03-24', '2018-04-21', '2019-11-16', '2020-03-05', '2020-05-10'], \n",
    "                          'age':33, 'gender':'M', \n",
    "                          'race_count':2, \n",
    "                          'training_elevation':5280, \n",
    "                          'max_hr':185}\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016-04-12',\n",
       " '2016-07-17',\n",
       " '2016-09-25',\n",
       " '2016-09-25',\n",
       " '2016-12-03',\n",
       " '2016-12-17',\n",
       " '2017-01-07',\n",
       " '2017-01-28',\n",
       " '2017-04-09',\n",
       " '2017-04-09',\n",
       " '2017-04-22',\n",
       " '2017-04-22',\n",
       " '2017-04-22',\n",
       " '2017-11-11',\n",
       " '2017-12-02',\n",
       " '2017-12-16',\n",
       " '2018-03-24',\n",
       " '2018-04-21',\n",
       " '2019-11-16',\n",
       " '2020-03-05',\n",
       " '2020-05-10']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = './data/races'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_num = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f'athlete_{athlete_num}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(parent_path, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_up_for_prediction(clean_filepath, test_athlete_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big problem with my data set is correcting pace, for the average elevation gain, and the heart rate of the individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting for elevation gain should be as simple as an energy balance: The potential energy taken away by moving the runner in the vertical direction should show a reduction in the speed in the horizontal direction, with some efficiency rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, heart rate should be a measure of the energy going in to the \"system\" and so should essentially be a gauge on the throttle of sorts. 100% throttle at a certain grade should yield a certain speed, or pace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ 0.5m\\nu_f^2 = 0.5m\\nu_i^2 - mgh$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simplifies down to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\nu_f = \\sqrt{\\nu_i^2-2gdC\\rho}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where ν_f is our final velocity, g is the gravitational constant, d is our distance, C is the feet per mile, and ρ is an efficiency constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see if we can correct pace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
