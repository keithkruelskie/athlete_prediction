{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PreProcessing Pipeline\n",
    "#Goal of this Notebook is to take all of the athletes in the race dictionary, and process all of their raw data files to make time series files for 1 month and 3 month histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_read_xml as pdx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garmin preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns all the filepaths as a list:\n",
    "filepaths = (glob.glob('./data/raw/Garmin/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/raw/Garmin/02_eric_bayless_updated.csv',\n",
       " './data/raw/Garmin/09_Riggs Activities r4 w favorites.csv',\n",
       " './data/raw/Garmin/04_BrianGetz_Activities.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the athletes.json athlete dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/athletes.json\") as json_file: \n",
    "    athletes = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-01-15', '2016-09-18', '2019-06-02']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turns a string from a json into its literal evaluation, in this case, a list:\n",
    "ast.literal_eval(athletes[\"1\"]['race_date_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of the races:\n",
    "list_of_races = [ast.literal_eval(athletes[str(i)]['race_date_list']) for i in range(len(athletes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_races_zipped = list(zip(filepaths, list_of_races))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define my inputs:\n",
    "inputs = list(zip(athletes, files_races_zipped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing so I can use this with my below function:\n",
    "# for athlete, (filepath, race_dates) in inputs:\n",
    "#     print(athlete)\n",
    "#     print(filepath)\n",
    "#     print(race_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_transf_garmin2(filepath, athlete_id, race_dates): #Filepath is the csv filepath, athlete_id is a counter variable, race_dates is the list of race dates\n",
    "    \n",
    "    #Read in the dataframe:\n",
    "    df = pd.read_csv(filepath, encoding='latin1')\n",
    "    #Found out this is very important in garmin files:\n",
    "    df.replace('--', 0, inplace = True)\n",
    "    \n",
    "    #Create athlete_id, file type and race category column:\n",
    "    df['athlete_id'] = athlete_id\n",
    "    df['filetype'] = 'garmin'\n",
    "    df['is_race'] = 0\n",
    "    \n",
    "    #Apparently some garmins save different columns:\n",
    "    if 'Avg Speed' in df.columns:\n",
    "        print(\"We have an Avg Speed Column!\")\n",
    "        df['Avg Pace'] = 0\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            #print(df['Avg Speed'][i])\n",
    "            try:\n",
    "                df['Avg Pace'][i] = re.findall(\"\\d?\\d:\\d\\d\", df['Avg Speed'][i])[0]\n",
    "                #print(df['Avg_Pace'][i])\n",
    "            except:\n",
    "                df['Avg Pace'][i] = '00:00:00'\n",
    "        #Best we can do for now is set the best pace to the average pace:\n",
    "        df['Best Pace'] = df['Avg Pace']\n",
    "    \n",
    "    \n",
    "    #Define the columns to have their data types transformed:\n",
    "    obj_to_num_cols = ['Calories', 'Avg HR', 'Max HR', 'Aerobic TE', 'Avg Run Cadence', 'Max Run Cadence', 'Elev Gain', 'Elev Loss', 'Avg Run Cadence.1', 'Avg Power', 'Max Power']\n",
    "    pace_cols = ['Avg Pace', 'Best Pace']\n",
    "    \n",
    "    #Convert the numeric columns:\n",
    "    for col in obj_to_num_cols:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col].str.extract(r'd+'))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    #Convert the pace columns:\n",
    "    for col in pace_cols:\n",
    "        for i in range(len(df[col])):\n",
    "            try:\n",
    "                df[col][i] = pd.to_timedelta('00:'+df[col][i])\n",
    "            except:\n",
    "                #print(f'col={col}')\n",
    "                #print(f'i= {i}')\n",
    "                #print(f'df[col][i] = {df[col][i]}')\n",
    "                if df[col][i]==0:\n",
    "                    df[col][i] = pd.to_timedelta('00:00:00')\n",
    "                else:\n",
    "                    pass\n",
    "                pass\n",
    "    \n",
    "    #Clean up the column names:\n",
    "    #This is to remove the (R) logo so it doesn't cause any issues later:\n",
    "    r_logo = df.columns[df.columns.str.contains('Training Stress')][0][-1]\n",
    "    #Clean up the column names:\n",
    "    df.columns = df.columns.str.replace('/', '').str.lower().str.replace('.', '_').str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace(r_logo, '')\n",
    "    df.set_index(df['date'], inplace = True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    ###Write a function to change the race dates in race_dates to a '1'\n",
    "    \n",
    "    #Write out the file to the data folder:\n",
    "    df.to_csv(f'./data/clean/garmin_clean/clean_{athlete_id}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "We have an Avg Speed Column!\n",
      "1\n",
      "We have an Avg Speed Column!\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "Athlete 6 was not able to be imported.\n",
      "7\n",
      "8\n",
      "9\n",
      "Athlete 9 was not able to be imported.\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for athlete, (filepath, race_dates) in inputs:\n",
    "    print(athlete)\n",
    "    try:\n",
    "        import_transf_garmin2(filepath, athlete, race_dates)\n",
    "    except:\n",
    "        print(f'Athlete {athlete} was not able to be imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Didn't get athlete 6 or 9, so I did those manually in the scratch notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The  below function chops up the data and puts it into folders according to athlete #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_for_prediction(df_filepath, athlete_dict):\n",
    "    \n",
    "    '''\n",
    "    Inputs: csv filepath, and athlete dictionary\n",
    "    -Dictionary contains an entry for race date, keyed to athlete id\n",
    "    Outputs: \n",
    "        1) a csv with races indicated, indexed by time series\n",
    "        2) a csv with summary values for 1 week, 2 weeks, 1 month, 2 months, 3 months\n",
    "            - If values are not available, they will be 0s\n",
    "    '''\n",
    "    #Read in the csv:\n",
    "    working = pd.read_csv(df_filepath, index_col='date').drop('date.1', axis =1)\n",
    "    \n",
    "    athlete_id = working['athlete_id'][0]\n",
    "    #print(athlete_id)\n",
    "    \n",
    "    #get the race dates for the selected athlete: (note that the json file means I need to reference a string for the id)\n",
    "    race_dates = ast.literal_eval(athlete_dict[f\"{athlete_id}\"]['race_date_list'])\n",
    "    #print(race_dates)\n",
    "    #print(type(race_dates))\n",
    "    \n",
    "    #Set the index as a datetime:\n",
    "    working.index = pd.to_datetime(working.index)\n",
    "    \n",
    "    #Create a month interval: (we can multiply by 3 to get the 3 month values)\n",
    "    month = timedelta(31)\n",
    "    day = timedelta(1)\n",
    "    \n",
    "    #Create a time of day column:\n",
    "    time_of_day = [re.findall(\"\\d\\d:\\d\\d:\\d\\d\", working.index.to_series().astype('str')[i])[0] for i in range(len(working))]\n",
    "    \n",
    "    #Drop the hours and minutes and seconds:\n",
    "    working.index = pd.DatetimeIndex(working.index).normalize()\n",
    "    \n",
    "    #Label all of the races:\n",
    "    working['is_race'] = np.where(working.index.isin(race_dates), 1, 0)\n",
    "    \n",
    "    #Create a folder for the athlete to keep things tidy:\n",
    "    parent_path = './data/races'\n",
    "    directory = f'athlete_{athlete_id}'\n",
    "    path = os.path.join(parent_path, directory)\n",
    "    os.mkdir(path)\n",
    "    \n",
    "    \n",
    "    #select the last month and last 3 months of data from the working file, and export them as separate csvs to the 'races' folder:\n",
    "    \n",
    "    for i in range(len(race_dates)):\n",
    "        #i is the counter, find the 1 month and 3 month data:\n",
    "        rd = pd.to_datetime(race_dates[i])\n",
    "        race_1_mo_back = working[rd+day:rd-month]\n",
    "        race_1_mo_back.sort_index(inplace=True)\n",
    "        race_1_mo_back.to_csv(f'{path}/athlete_{athlete_id}_race_{i}_1_mo.csv')\n",
    "        try:\n",
    "            #This way if there is not 3 months data, it just skips out.\n",
    "            race_3_mo_back = working[rd+day:(rd-month*3)]\n",
    "            race_3_mo_back.sort_index(inplace=True)\n",
    "            race_3_mo_back.to_csv(f'{path}/athlete_{athlete_id}_race_{i}_3_mo.csv')\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_filepaths = (glob.glob('./data/clean/garmin_clean/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/clean/garmin_clean/clean_6.csv',\n",
       " './data/clean/garmin_clean/clean_7.csv',\n",
       " './data/clean/garmin_clean/clean_5.csv',\n",
       " './data/clean/garmin_clean/clean_4.csv',\n",
       " './data/clean/garmin_clean/clean_0.csv',\n",
       " './data/clean/garmin_clean/clean_1.csv',\n",
       " './data/clean/garmin_clean/clean_3.csv',\n",
       " './data/clean/garmin_clean/clean_2.csv',\n",
       " './data/clean/garmin_clean/clean_12.csv',\n",
       " './data/clean/garmin_clean/clean_11.csv',\n",
       " './data/clean/garmin_clean/clean_10.csv',\n",
       " './data/clean/garmin_clean/clean_9.csv',\n",
       " './data/clean/garmin_clean/clean_8.csv']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in clean_filepaths:\n",
    "    set_up_for_prediction(filepath, athletes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strava preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
